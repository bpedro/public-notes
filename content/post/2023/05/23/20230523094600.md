---
date: 2023-05-23T09:46:00+02:00
tags:
  - ai
  - speech
  - language
  - translation
  - understanding
---
{{% marginnote %}}Found at "[fairseqexamplesmms at main · facebookresearchfairseq · GitHub](https://web.archive.org/web/20230523094600/https://github.com/facebookresearch/fairseq/tree/main/examples/mms)" on 2023-05-23 09:46:00 +02:00.{{% /marginnote %}}

This could be possibly used to scale human-to-AI interaction in thousands of languages.

> The Massively Multilingual Speech (MMS) project expands speech technology from about 100 languages to over 1,000 by building a single multilingual speech recognition model supporting over 1,100 languages (more than 10 times as many as before), language identification models able to identify over [4,000 languages](https://dl.fbaipublicfiles.com/mms/misc/language_coverage_mms.html) (40 times more than before), pretrained models supporting over 1,400 languages, and text-to-speech models for over 1,100 languages. Our goal is to make it easier for people to access information and to use devices in their preferred language.