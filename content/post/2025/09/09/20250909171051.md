---
title: 
date: 2025-09-09T17:10:51+02:00
summary: Evals tools and frameworks
tags:
  - ai
  - testing
  - evals
  - open-source
---
Here's a list of evals tools and frameworks I've been profiling:

- [OpenAI Evals](https://github.com/openai/evals): Open-source, from OpenAI.
- [LangSmith](https://www.langchain.com/langsmith): Observability and Evals.
- [PromptPex](https://github.com/microsoft/promptpex): More focused on prompt testing.
- [ChainForge](https://www.chainforge.ai/): Prompt robustness testing visual UI.
- [PromptLayer](https://www.promptlayer.com/): Full end-to-end AI testing and monitoring.
- [Garak](https://github.com/NVIDIA/garak): Security-focused, from NVIDIA.

{{< figure src="/media/ChainForge.png" title="ChainForge example flow" caption="In this example ChainForge evaluates model robustness to prompt injection attacks." >}}